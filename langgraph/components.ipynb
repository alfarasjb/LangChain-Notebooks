{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "\n",
    "load_dotenv() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END \n",
    "from typing import TypedDict, Annotated \n",
    "import operator \n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage \n",
    "from langchain_openai import ChatOpenAI \n",
    "from langchain_community.tools.tavily_search import TavilySearchResults \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=4) \n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict): \n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent: \n",
    "    def __init__(self, model, tools, system: str = \"\"):\n",
    "        self.system = system \n",
    "        graph = StateGraph(AgentState) \n",
    "        graph.add_node(\"llm\", self.call_openai)  \n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            { True: \"action\", False: END }\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile() \n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "    \n",
    "    def exists_action(self, state: AgentState): \n",
    "        result = state['messages'][-1] \n",
    "        return len(result.tool_calls) > 0 \n",
    "\n",
    "    def take_action(self, state: AgentState): \n",
    "        tool_calls = state['messages'][-1].tool_calls \n",
    "        results = [] \n",
    "        for t in tool_calls: \n",
    "            print(f\"Calling: {t}\") \n",
    "            if not t['name'] in self.tools: \n",
    "                print(\"\\n... Bad tool Name ...\") \n",
    "                result = \"bad tool name, retry\"\n",
    "            else: \n",
    "                result = self.tools[t['name']].invoke(t['args']) \n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        return {'messages': results}\n",
    "\n",
    "    def call_openai(self, state: AgentState): \n",
    "        messages = state['messages']\n",
    "        if self.system: \n",
    "            messages = [SystemMessage(content=self.system)] + messages \n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "import os\n",
    "model = ChatOpenAI(model=\"gpt-4o\", api_key=os.getenv('OPENAI_API_KEY'))  #reduce inference cost\n",
    "abot = Agent(model, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "\n",
    "# Image(abot.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather current'}, 'id': 'call_dqaIiCOvcDPnxDYOjqH0IFiY', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in San Francisco is clear with a temperature of 10.1°C (50.2°F). The wind is blowing from the north-northeast at 5.4 mph (8.6 kph), and the humidity level is 50%. The visibility is good, with a distance of 16 km (9 miles).'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_XJo7Be6CBgzsqVEL9oRTjFIh', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_OG9L4omsY6WNEa3WmcKFjsxh', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF and LA?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in San Francisco is clear with a temperature of 10.1°C (50.2°F). The wind is blowing from the north-northeast at 5.4 mph (8.6 kph), and the humidity is at 50%.\\n\\nIn Los Angeles, the weather is also clear, with a temperature of 13.3°C (55.9°F). The wind is coming from the north-northeast at 6.9 mph (11.2 kph), and the humidity is at 20%.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Super Bowl 2024 winner'}, 'id': 'call_p7CUNJaQ2zqXNp8oy0jBntkF', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Kansas City Chiefs headquarters location'}, 'id': 'call_ghZ8tyEfqArdF8T89rfiVBng', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Missouri GDP 2024'}, 'id': 'call_VoQKyjIrv46CaWNDgKWRxiPs', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "source": [
    "# Note, the query was modified to produce more consistent results. \n",
    "# Results may vary per run and over time as search information and models change.\n",
    "\n",
    "query = \"Who won the super bowl in 2024? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")  # requires more advanced model\n",
    "abot = Agent(model, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Who won the Super Bowl in 2024?**  \n",
      "   The Kansas City Chiefs won the Super Bowl in 2024, defeating the San Francisco 49ers 25-22 in overtime.\n",
      "\n",
      "2. **In what state is the winning team's headquarters located?**  \n",
      "   The headquarters of the Kansas City Chiefs is located in Missouri.\n",
      "\n",
      "3. **What is the GDP of that state?**  \n",
      "   As of the third quarter of 2024, Missouri's GDP was approximately $454.58 billion.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pioneerdevai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
